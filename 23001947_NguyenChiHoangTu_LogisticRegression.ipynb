{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# A2",
   "id": "7823986b91433dc7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import math\n",
    "from itertools import count\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn.external.docscrape import header"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:12:54.756378Z",
     "start_time": "2025-10-16T14:12:54.745822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('vidu4_lin_reg.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "x_data = []\n",
    "ntm = []\n",
    "y_data = []\n",
    "lines.pop(0)\n",
    "\n",
    "for line in lines:\n",
    "    splitted = line.replace('\\n', '').split(' ')\n",
    "    splitted.pop(0)\n",
    "    splitted = list(map(float, splitted))\n",
    "    x_data.append(splitted[:5])\n",
    "    ntm.append(splitted[5])\n",
    "\n",
    "x_data = np.asarray(x_data)\n",
    "y_data = np.zeros(len(ntm))\n",
    "for i in range(len(y_data)):\n",
    "    if ntm[i] >= 1:\n",
    "        y_data[i] = 1\n",
    "    else:\n",
    "        y_data[i] = 0\n",
    "y_data = np.asarray(y_data)\n",
    "print(y_data)"
   ],
   "id": "bfaa6607592b3701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "execution_count": 543
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:12:56.771017Z",
     "start_time": "2025-10-16T14:12:56.764324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k = 6\n",
    "def distance(array, value):\n",
    "    array = np.array(array)\n",
    "    return np.linalg.norm(array - value,ord=2, axis=1)\n",
    "\n",
    "def find_nearest_index(array, value, k):\n",
    "    array_D = distance(array, value)\n",
    "    return np.argsort(array_D)[:k]\n",
    "\n",
    "data_len = len(x_data)\n",
    "\n",
    "X_train = np.array(x_data[:80])\n",
    "Y_train = np.array(y_data[:80])\n",
    "X_test = np.array(x_data[80:data_len])\n",
    "Y_test = np.array(y_data[80:data_len])"
   ],
   "id": "34020b50c5e855c7",
   "outputs": [],
   "execution_count": 544
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:12:58.220470Z",
     "start_time": "2025-10-16T14:12:58.210916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y_pred = np.zeros(len(X_test))\n",
    "for i in range(len(X_test)):\n",
    "    indexis = find_nearest_index(X_train, X_test[i], k)\n",
    "    for id in indexis:\n",
    "        Y_pred[i] = Y_pred[i] + Y_train[id]\n",
    "    Y_pred[i] = Y_pred[i]/len(indexis)\n",
    "    if Y_pred[i] >= 0.5:\n",
    "        Y_pred[i] = 1\n",
    "    else:\n",
    "        Y_pred[i] = 0\n",
    "    print(Y_pred[i], ' | ', Y_test[i])"
   ],
   "id": "a97979f76b2a2b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0  |  0.0\n",
      "1.0  |  0.0\n",
      "1.0  |  1.0\n",
      "1.0  |  0.0\n",
      "1.0  |  0.0\n",
      "0.0  |  0.0\n",
      "1.0  |  1.0\n",
      "1.0  |  0.0\n",
      "1.0  |  1.0\n",
      "0.0  |  0.0\n",
      "1.0  |  0.0\n",
      "0.0  |  0.0\n",
      "1.0  |  1.0\n",
      "0.0  |  1.0\n",
      "0.0  |  1.0\n",
      "0.0  |  0.0\n",
      "1.0  |  1.0\n",
      "1.0  |  1.0\n",
      "1.0  |  0.0\n",
      "0.0  |  1.0\n"
     ]
    }
   ],
   "execution_count": 545
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:11.514002Z",
     "start_time": "2025-10-16T14:13:11.503160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "Y_pred = Y_pred.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "acc = accuracy_score(Y_test, Y_pred)\n",
    "prec = precision_score(Y_test, Y_pred)\n",
    "rec = recall_score(Y_test, Y_pred)\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print(\"\\n=== Evaluation Metrics ===\")\n",
    "print(f\"Accuracy : {acc:.2f}\")\n",
    "print(f\"Precision: {prec:.2f}\")\n",
    "print(f\"Recall   : {rec:.2f}\")\n"
   ],
   "id": "6c5c70616a16396",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Metrics ===\n",
      "Accuracy : 0.55\n",
      "Precision: 0.50\n",
      "Recall   : 0.67\n"
     ]
    }
   ],
   "execution_count": 547
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# B√†i 1",
   "id": "e59256f1867c965b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logistic Regression",
   "id": "371c39b2b97b95b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:14.227104Z",
     "start_time": "2025-10-16T14:13:14.221499Z"
    }
   },
   "cell_type": "code",
   "source": [
    " import numpy as np\n",
    " import pandas as pd"
   ],
   "id": "7296aac4936f862f",
   "outputs": [],
   "execution_count": 548
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:15.589015Z",
     "start_time": "2025-10-16T14:13:15.577272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"Admission_Predict.csv\")\n",
    "sn = data['Serial No.'].tolist()\n",
    "\n",
    "gre = data['GRE Score'].tolist()\n",
    "X1 = np.asarray(gre)\n",
    "\n",
    "tfl = data['TOEFL Score'].tolist()\n",
    "X2 = np.asarray(tfl)\n",
    "\n",
    "unirt = data['University Rating'].tolist()\n",
    "X3 = np.asarray(unirt)\n",
    "\n",
    "sop = data['SOP'].tolist()\n",
    "X4 = np.asarray(sop)\n",
    "\n",
    "lor1 = data['LOR '].tolist()\n",
    "X5 = np.asarray(lor1)\n",
    "\n",
    "cgpa1 = data['CGPA'].tolist()\n",
    "X6 = np.asarray(cgpa1)\n",
    "\n",
    "research_exp = data['Research'].tolist()\n",
    "X7 = np.asarray(research_exp)\n",
    "\n",
    "prob_Admit = data['Chance of Admit'].tolist()\n",
    "Yt = np.asarray(prob_Admit)\n",
    "\n"
   ],
   "id": "c685e5d13fcb39fd",
   "outputs": [],
   "execution_count": 549
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:17.329072Z",
     "start_time": "2025-10-16T14:13:17.320738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(s):\n",
    "    s = np.clip(s, -500, 500)\n",
    "    return 1/(1 + np.exp(-s))\n",
    "\n",
    "def logistic_sigmoid_regression(X, y, w_init, eta, tol = 1e-4, max_count = 10000):\n",
    "    # method to calculate model logistic regression by Stochastic Gradient Descent method\n",
    "    # eta: learning rate; tol: tolerance; max_count: maximum iterates\n",
    "    w = [w_init]\n",
    "    it = 0\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    count = 0\n",
    "    check_w_after = 20\n",
    "    # loop of stochastic gradient descent\n",
    "    while count < max_count:\n",
    "    # shuffle the order of data (for stochastic gradient descent).\n",
    "    # and put into mix_id\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = y[i]\n",
    "            zi = sigmoid(np.dot(w[-1].T, xi))\n",
    "            w_new = w[-1] + eta*(yi - zi)*xi\n",
    "            count += 1\n",
    "            # stopping criteria\n",
    "            if count%check_w_after == 0:\n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol:\n",
    "                    return w\n",
    "            w.append(w_new)\n",
    "    return w"
   ],
   "id": "5553c6dfe37a09a7",
   "outputs": [],
   "execution_count": 550
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:19.256358Z",
     "start_time": "2025-10-16T14:13:19.249823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y = np.array([1 if p >= 0.75 else 0 for p in Yt])\n",
    "X = np.stack((X1, X2, X3, X4, X5, X6, X7), axis=0)\n",
    "Xbar = np.concatenate((np.ones((1, X.shape[1])), X), axis=0).T"
   ],
   "id": "1afc91e40d6ee253",
   "outputs": [],
   "execution_count": 551
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:20.660973Z",
     "start_time": "2025-10-16T14:13:20.656390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = Xbar[:350,:]\n",
    "Y_train = Y[:350]\n",
    "X_test = Xbar[350:,:]\n",
    "Y_test = Y[350:]"
   ],
   "id": "24afc27bc03246f1",
   "outputs": [],
   "execution_count": 552
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:34.564535Z",
     "start_time": "2025-10-16T14:13:34.412935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d = X_train.shape[1]\n",
    "w_init = np.random.randn(d,1)\n",
    "eta = .05\n",
    "w = logistic_sigmoid_regression(X_train.T, Y_train, w_init, eta)\n",
    "print(w[-1])"
   ],
   "id": "39db8d76cec00a72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.85496782]\n",
      " [-72.18562892]\n",
      " [202.68714634]\n",
      " [139.69520769]\n",
      " [110.05627657]\n",
      " [ 90.62185502]\n",
      " [ 42.16971288]\n",
      " [ 57.95083707]]\n"
     ]
    }
   ],
   "execution_count": 559
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:36.813114Z",
     "start_time": "2025-10-16T14:13:36.802684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_prod = sigmoid(np.dot(w[-1].T, X_test.T)).flatten()\n",
    "y_pred = (y_prod >= 0.5).astype(int)\n",
    "print(\"C√°c h·ªá s·ªë c·ªßa m√¥ h√¨nh (w):\")\n",
    "print(w[-1].flatten())\n",
    "TP = np.sum((y_pred == 1) & (Y_test == 1))\n",
    "TN = np.sum((y_pred == 0) & (Y_test == 0))\n",
    "FP = np.sum((y_pred == 1) & (Y_test == 0))\n",
    "FN = np.sum((y_pred == 0) & (Y_test == 1))\n",
    "\n",
    "accuracy = (TP + TN) / len(Y_test)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "print(f\"\\nƒê·ªô ch√≠nh x√°c (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"ƒê·ªô ch√≠nh x√°c d∆∞∆°ng (Precision): {precision:.4f}\")\n",
    "print(f\"ƒê·ªô nh·∫°y (Recall): {recall:.4f}\")\n",
    "for i in range(len(y_pred)):\n",
    "    print(f\"{y_pred[i]} || {Y_test[i]}\")"
   ],
   "id": "b0f609e947371eb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√°c h·ªá s·ªë c·ªßa m√¥ h√¨nh (w):\n",
      "[ -5.85496782 -72.18562892 202.68714634 139.69520769 110.05627657\n",
      "  90.62185502  42.16971288  57.95083707]\n",
      "\n",
      "ƒê·ªô ch√≠nh x√°c (Accuracy): 0.7600\n",
      "ƒê·ªô ch√≠nh x√°c d∆∞∆°ng (Precision): 0.7083\n",
      "ƒê·ªô nh·∫°y (Recall): 0.7727\n",
      "1 || 0\n",
      "1 || 0\n",
      "0 || 0\n",
      "1 || 0\n",
      "0 || 0\n",
      "0 || 0\n",
      "1 || 1\n",
      "1 || 0\n",
      "0 || 0\n",
      "0 || 1\n",
      "1 || 1\n",
      "1 || 1\n",
      "1 || 1\n",
      "0 || 0\n",
      "0 || 1\n",
      "1 || 1\n",
      "0 || 0\n",
      "0 || 0\n",
      "0 || 0\n",
      "0 || 0\n",
      "0 || 0\n",
      "1 || 1\n",
      "1 || 1\n",
      "1 || 1\n",
      "0 || 0\n",
      "0 || 0\n",
      "0 || 0\n",
      "1 || 0\n",
      "0 || 0\n",
      "0 || 0\n",
      "0 || 1\n",
      "0 || 0\n",
      "1 || 1\n",
      "1 || 0\n",
      "1 || 1\n",
      "1 || 1\n",
      "0 || 0\n",
      "1 || 0\n",
      "0 || 0\n",
      "1 || 1\n",
      "0 || 0\n",
      "0 || 0\n",
      "1 || 1\n",
      "0 || 1\n",
      "1 || 1\n",
      "1 || 1\n",
      "0 || 1\n",
      "1 || 1\n",
      "0 || 0\n",
      "1 || 1\n"
     ]
    }
   ],
   "execution_count": 560
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression",
   "id": "a6f78771ab5f4614"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:41.497748Z",
     "start_time": "2025-10-16T14:13:41.494488Z"
    }
   },
   "cell_type": "code",
   "source": [
    " import numpy as np\n",
    " import pandas as pd\n",
    " import math"
   ],
   "id": "c19899b394796450",
   "outputs": [],
   "execution_count": 561
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:42.805359Z",
     "start_time": "2025-10-16T14:13:42.793606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"Admission_Predict.csv\")\n",
    "sn = data['Serial No.'].tolist()\n",
    "\n",
    "gre = data['GRE Score'].tolist()\n",
    "X1 = np.asarray(gre)\n",
    "\n",
    "tfl = data['TOEFL Score'].tolist()\n",
    "X2 = np.asarray(tfl)\n",
    "\n",
    "unirt = data['University Rating'].tolist()\n",
    "X3 = np.asarray(unirt)\n",
    "\n",
    "sop = data['SOP'].tolist()\n",
    "X4 = np.asarray(sop)\n",
    "\n",
    "lor1 = data['LOR '].tolist()\n",
    "X5 = np.asarray(lor1)\n",
    "\n",
    "cgpa1 = data['CGPA'].tolist()\n",
    "X6 = np.asarray(cgpa1)\n",
    "\n",
    "research_exp = data['Research'].tolist()\n",
    "X7 = np.asarray(research_exp)\n",
    "\n",
    "prob_Admit = data['Chance of Admit'].tolist()\n",
    "Yt = np.asarray(prob_Admit)\n",
    "\n"
   ],
   "id": "7576634d8e2c82f7",
   "outputs": [],
   "execution_count": 562
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:44.501730Z",
     "start_time": "2025-10-16T14:13:44.496681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y = np.asarray(np.array([1 if p >= 0.75 else 0 for p in Yt]))\n",
    "X = np.asarray(np.stack((X1, X2, X3, X4, X5, X6, X7), axis=0).T)"
   ],
   "id": "aa332484b5c74326",
   "outputs": [],
   "execution_count": 563
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:45.805867Z",
     "start_time": "2025-10-16T14:13:45.799347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def qr_householder(A):\n",
    "    M, N = A.shape\n",
    "    Q = np.eye(M)\n",
    "    R = A.copy().astype(float)\n",
    "\n",
    "    for n in range(N):\n",
    "        x = R[n:, n]\n",
    "        ro = -np.sign(x[0]) * np.linalg.norm(x)\n",
    "        v = x.copy()\n",
    "        v[0] -= ro\n",
    "        v /= np.linalg.norm(v)\n",
    "\n",
    "        R[n:, :] -= 2 * np.outer(v, v @ R[n:, :])\n",
    "        Q[:, n:] -= 2 * np.outer(Q[:, n:] @ v, v)\n",
    "\n",
    "    return Q, R"
   ],
   "id": "714c5cd0e89bf",
   "outputs": [],
   "execution_count": 564
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:47.282287Z",
     "start_time": "2025-10-16T14:13:47.276593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_regression(x_data, y_data):\n",
    "    X_bar = np.concatenate((np.ones((x_data.shape[0], 1)), x_data), axis=1)\n",
    "    Q, R = qr_householder(X_bar)\n",
    "    N = X_bar.shape[1]\n",
    "    R1 = R[:N, :]\n",
    "    Q1 = Q[:, :N]\n",
    "    w = np.linalg.inv(R1) @ Q1.T @ y_data\n",
    "    return w"
   ],
   "id": "f10e153936400a39",
   "outputs": [],
   "execution_count": 565
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:48.721402Z",
     "start_time": "2025-10-16T14:13:48.716125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train = X[:350,:]\n",
    "y_train = Y[:350]\n",
    "x_test = X[350:,:]\n",
    "y_test = Y[350:]"
   ],
   "id": "3ee166ccfc50d2e2",
   "outputs": [],
   "execution_count": 566
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:50.074795Z",
     "start_time": "2025-10-16T14:13:50.049578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w = linear_regression(x_train, y_train)\n",
    "print(\"\\nSo s√°nh gi√° tr·ªã th·ª±c t·∫ø v√† d·ª± ƒëo√°n (t·∫≠p test):\")\n",
    "print(f\"{'STT':>3} | {'Th·ª±c t·∫ø (y_test)':>15} | {'D·ª± ƒëo√°n (y_pred)':>17} | {'Sai s·ªë (error)':>15}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"{i+1:3d} | {y_test[i]:15.0f} | {y_pred[i]:17.0f}\")\n",
    "\n",
    "mse = np.mean((y_pred - y_test) ** 2)\n",
    "print(\"Trung b√¨nh b√¨nh ph∆∞∆°ng sai s·ªë (MSE):\", mse)\n",
    "y_class = (y_pred >= 0.5).astype(int)\n",
    "accuracy = np.mean(y_class == y_test)\n",
    "print(\"ƒê·ªô ch√≠nh x√°c:\", accuracy)"
   ],
   "id": "44980e831a6a4ee2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "So s√°nh gi√° tr·ªã th·ª±c t·∫ø v√† d·ª± ƒëo√°n (t·∫≠p test):\n",
      "STT | Th·ª±c t·∫ø (y_test) |  D·ª± ƒëo√°n (y_pred) |  Sai s·ªë (error)\n",
      "------------------------------------------------------------\n",
      "  1 |               0 |                 1\n",
      "  2 |               0 |                 1\n",
      "  3 |               0 |                 0\n",
      "  4 |               0 |                 1\n",
      "  5 |               0 |                 0\n",
      "  6 |               0 |                 0\n",
      "  7 |               1 |                 1\n",
      "  8 |               0 |                 1\n",
      "  9 |               0 |                 0\n",
      " 10 |               1 |                 0\n",
      " 11 |               1 |                 1\n",
      " 12 |               1 |                 1\n",
      " 13 |               1 |                 1\n",
      " 14 |               0 |                 0\n",
      " 15 |               1 |                 0\n",
      " 16 |               1 |                 1\n",
      " 17 |               0 |                 0\n",
      " 18 |               0 |                 0\n",
      " 19 |               0 |                 0\n",
      " 20 |               0 |                 0\n",
      " 21 |               0 |                 0\n",
      " 22 |               1 |                 1\n",
      " 23 |               1 |                 1\n",
      " 24 |               1 |                 1\n",
      " 25 |               0 |                 0\n",
      " 26 |               0 |                 0\n",
      " 27 |               0 |                 0\n",
      " 28 |               0 |                 1\n",
      " 29 |               0 |                 0\n",
      " 30 |               0 |                 0\n",
      " 31 |               1 |                 0\n",
      " 32 |               0 |                 0\n",
      " 33 |               1 |                 1\n",
      " 34 |               0 |                 1\n",
      " 35 |               1 |                 1\n",
      " 36 |               1 |                 1\n",
      " 37 |               0 |                 0\n",
      " 38 |               0 |                 1\n",
      " 39 |               0 |                 0\n",
      " 40 |               1 |                 1\n",
      " 41 |               0 |                 0\n",
      " 42 |               0 |                 0\n",
      " 43 |               1 |                 1\n",
      " 44 |               1 |                 0\n",
      " 45 |               1 |                 1\n",
      " 46 |               1 |                 1\n",
      " 47 |               1 |                 0\n",
      " 48 |               1 |                 1\n",
      " 49 |               0 |                 0\n",
      " 50 |               1 |                 1\n",
      "Trung b√¨nh b√¨nh ph∆∞∆°ng sai s·ªë (MSE): 0.24\n",
      "ƒê·ªô ch√≠nh x√°c: 0.76\n"
     ]
    }
   ],
   "execution_count": 567
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Naive Bayes",
   "id": "73c5e11a56eb730f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:57.118193Z",
     "start_time": "2025-10-16T14:13:57.112599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import sqrt, pi, exp"
   ],
   "id": "1755664ee1993220",
   "outputs": [],
   "execution_count": 568
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:58.439606Z",
     "start_time": "2025-10-16T14:13:58.426948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"Admission_Predict.csv\")\n",
    "X = data[['GRE Score', 'TOEFL Score', 'University Rating',\n",
    "          'SOP', 'LOR ', 'CGPA', 'Research']].values\n",
    "Yt = data['Chance of Admit'].values\n",
    "Y = np.array([1 if p >= 0.75 else 0 for p in Yt])\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ],
   "id": "fafbce70f8567232",
   "outputs": [],
   "execution_count": 569
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:13:59.962701Z",
     "start_time": "2025-10-16T14:13:59.859484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_sgd(X, y, eta=0.01, tol=1e-4, max_iter=10000):\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros((n_features, 1))\n",
    "    y = y.reshape(-1, 1)\n",
    "    prev_w = w.copy()\n",
    "    for i in range(max_iter):\n",
    "        idx = np.random.randint(0, n_samples)\n",
    "        xi = X[idx].reshape(-1, 1)\n",
    "        yi = y[idx]\n",
    "        zi = sigmoid(np.dot(w.T, xi))\n",
    "        w += eta * (yi - zi) * xi\n",
    "        if i % 500 == 0 and np.linalg.norm(w - prev_w) < tol:\n",
    "            break\n",
    "        prev_w = w.copy()\n",
    "    return w\n",
    "\n",
    "# H√†m ƒë√°nh gi√°\n",
    "def evaluate(y_true, y_pred):\n",
    "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    TN = np.sum((y_pred == 0) & (y_true == 0))\n",
    "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
    "\n",
    "    accuracy = (TP + TN) / len(y_true)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    return accuracy, precision, recall, (TP, TN, FP, FN)\n",
    "\n",
    "# Th√™m c·ªôt bias 1\n",
    "Xbar = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "\n",
    "# Logistic Regression\n",
    "start_lr = time.time()\n",
    "w = logistic_sgd(Xbar, Y, eta=0.01)\n",
    "y_prob = sigmoid(np.dot(Xbar, w))\n",
    "y_pred_lr = (y_prob >= 0.5).astype(int).flatten()\n",
    "end_lr = time.time()\n",
    "\n",
    "acc_lr, pre_lr, rec_lr, conf_lr = evaluate(Y, y_pred_lr)"
   ],
   "id": "8c5e9076929d120c",
   "outputs": [],
   "execution_count": 570
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:01.994160Z",
     "start_time": "2025-10-16T14:14:01.961496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gaussian_prob(x, mean, std):\n",
    "    std = max(std, 1e-6)\n",
    "    return (1 / (sqrt(2 * pi) * std)) * exp(- ((x - mean) ** 2) / (2 * std ** 2))\n",
    "\n",
    "def train_gnb(X, y):\n",
    "    classes = np.unique(y)\n",
    "    mu_list = []\n",
    "    std_list = []\n",
    "    pi_list = []\n",
    "    for c in classes:\n",
    "        X_c = X[y == c]\n",
    "        mu_list.append(X_c.mean(axis=0))\n",
    "        std_list.append(X_c.std(axis=0))\n",
    "        pi_list.append(len(X_c) / len(X))\n",
    "    return np.array(mu_list), np.array(std_list), np.array(pi_list)\n",
    "\n",
    "def predict_gnb(X, mu_list, std_list, pi_list):\n",
    "    y_pred = []\n",
    "    for x in X:\n",
    "        scores = []\n",
    "        for mu, std, pi in zip(mu_list, std_list, pi_list):\n",
    "            likelihood = np.prod([gaussian_prob(xi, mui, si) for xi, mui, si in zip(x, mu, std)])\n",
    "            scores.append(likelihood * pi)\n",
    "        y_pred.append(np.argmax(scores))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "start_nb = time.time()\n",
    "mu_list, std_list, pi_list = train_gnb(X, Y)\n",
    "y_pred_nb = predict_gnb(X, mu_list, std_list, pi_list)\n",
    "end_nb = time.time()\n",
    "\n",
    "acc_nb, pre_nb, rec_nb, conf_nb = evaluate(Y, y_pred_nb)"
   ],
   "id": "68cb4af9f6cc0ea7",
   "outputs": [],
   "execution_count": 571
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:03.728452Z",
     "start_time": "2025-10-16T14:14:03.690134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_nb = time.time()\n",
    "mu_list, std_list, pi_list = train_gnb(X, Y)\n",
    "y_pred_nb = predict_gnb(X, mu_list, std_list, pi_list)\n",
    "end_nb = time.time()\n",
    "\n",
    "acc_nb, pre_nb, rec_nb, conf_nb = evaluate(Y, y_pred_nb)\n",
    "\n",
    "print(\"üîπ Logistic Regression (SGD)\")\n",
    "print(f\"Accuracy : {acc_lr:.4f}, Precision: {pre_lr:.4f}, Recall: {rec_lr:.4f}\")\n",
    "print(f\"Time     : {end_lr - start_lr:.4f}s\")\n",
    "print(f\"Confusion (TP, TN, FP, FN): {conf_lr}\\n\")\n",
    "\n",
    "print(\"üîπ Gaussian Naive Bayes\")\n",
    "print(f\"Accuracy : {acc_nb:.4f}, Precision: {pre_nb:.4f}, Recall: {rec_nb:.4f}\")\n",
    "print(f\"Time     : {end_nb - start_nb:.4f}s\")\n",
    "print(f\"Confusion (TP, TN, FP, FN): {conf_nb}\\n\")\n",
    "\n",
    "print(\"üî∏ So s√°nh t·ªïng k·∫øt:\")\n",
    "print(\"Thu·∫≠t to√°n                  Accuracy    Precision     Recall    Time(s)\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(f\"Logistic Regression (SGD)     {acc_lr:.3f}        {pre_lr:.3f}      {rec_lr:.3f}     {(end_lr - start_lr):.4f}\")\n",
    "print(f\"Gaussian Naive Bayes          {acc_nb:.3f}        {pre_nb:.3f}      {rec_nb:.3f}     {(end_nb - start_nb):.4f}\")\n"
   ],
   "id": "5ab7b37ffcd65cdb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Logistic Regression (SGD)\n",
      "Accuracy : 0.8750, Precision: 0.8736, Recall: 0.8444\n",
      "Time     : 0.0690s\n",
      "Confusion (TP, TN, FP, FN): (np.int64(152), np.int64(198), np.int64(22), np.int64(28))\n",
      "\n",
      "üîπ Gaussian Naive Bayes\n",
      "Accuracy : 0.8700, Precision: 0.8721, Recall: 0.8333\n",
      "Time     : 0.0278s\n",
      "Confusion (TP, TN, FP, FN): (np.int64(150), np.int64(198), np.int64(22), np.int64(30))\n",
      "\n",
      "üî∏ So s√°nh t·ªïng k·∫øt:\n",
      "Thu·∫≠t to√°n                  Accuracy    Precision     Recall    Time(s)\n",
      "----------------------------------------------------------------------\n",
      "Logistic Regression (SGD)     0.875        0.874      0.844     0.0690\n",
      "Gaussian Naive Bayes          0.870        0.872      0.833     0.0278\n"
     ]
    }
   ],
   "execution_count": 572
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## D√πng th∆∞ vi·ªán Scikit-Learn",
   "id": "383ed68d53a5f708"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:10.307381Z",
     "start_time": "2025-10-16T14:14:10.268086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "data = pd.read_csv(\"Admission_Predict.csv\")\n",
    "X = data[['GRE Score','TOEFL Score','University Rating','SOP','LOR ','CGPA','Research']].values\n",
    "Yt = data['Chance of Admit'].values\n",
    "Y = np.array([1 if p >= 0.75 else 0 for p in Yt])\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "start = time.time()\n",
    "logReg = linear_model.LogisticRegression(penalty='l2', max_iter=10000)\n",
    "logReg.fit(X, Y)\n",
    "end = time.time()\n",
    "\n",
    "Y_pred = logReg.predict(X)\n",
    "\n",
    "acc = accuracy_score(Y, Y_pred)\n",
    "prec = precision_score(Y, Y_pred)\n",
    "rec = recall_score(Y, Y_pred)\n",
    "cm = confusion_matrix(Y, Y_pred)\n",
    "\n",
    "print(\"üîπ Logistic Regression (Scikit-learn)\")\n",
    "print(f\"Accuracy : {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
    "print(f\"Time     : {end - start:.4f}s\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"\\nC√°c h·ªá s·ªë w:\")\n",
    "print(logReg.coef_)\n",
    "print(\"Intercept:\", logReg.intercept_)\n"
   ],
   "id": "fa80674b6f23d173",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Logistic Regression (Scikit-learn)\n",
      "Accuracy : 0.8875, Precision: 0.8902, Recall: 0.8556\n",
      "Time     : 0.0177s\n",
      "Confusion matrix:\n",
      " [[201  19]\n",
      " [ 26 154]]\n",
      "\n",
      "C√°c h·ªá s·ªë w:\n",
      "[[0.57504585 0.53335519 0.38708674 0.4194294  0.36231289 1.85302956\n",
      "  0.39521135]]\n",
      "Intercept: [-0.4647888]\n"
     ]
    }
   ],
   "execution_count": 573
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:12.421905Z",
     "start_time": "2025-10-16T14:14:12.379907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# ==============================================================\n",
    "# üü¶ B·ªò D·ªÆ LI·ªÜU 1: D·ªÆ LI·ªÜU 1 CHI·ªÄU (X, y)\n",
    "# ==============================================================\n",
    "X = np.array([[0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 1.75, 2.00, 2.25, 2.50,\n",
    "               2.75, 3.00, 3.25, 3.50, 4.00, 4.25, 4.50, 4.75, 5.00, 5.50]]).T\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
    "              1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "start = time.time()\n",
    "logReg1 = linear_model.LogisticRegression(penalty='l2')\n",
    "logReg1.fit(X, y)\n",
    "end = time.time()\n",
    "\n",
    "y_pred1 = logReg1.predict(X)\n",
    "\n",
    "print(\"üîπ [B·ªô 1D] Logistic Regression (Scikit-learn)\")\n",
    "print(\"Coefficients:\", logReg1.coef_)\n",
    "print(\"Intercept   :\", logReg1.intercept_)\n",
    "print(\"Accuracy :\", accuracy_score(y, y_pred1))\n",
    "print(\"Precision:\", precision_score(y, y_pred1))\n",
    "print(\"Recall   :\", recall_score(y, y_pred1))\n",
    "print(\"Time     :\", end - start)\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y, y_pred1))\n",
    "print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# ==============================================================\n",
    "# üü© B·ªò D·ªÆ LI·ªÜU 2: D·ªÆ LI·ªÜU 2 CHI·ªÄU NG·∫™U NHI√äN (X1, X2)\n",
    "# ==============================================================\n",
    "means = [[2, 2], [4, 2]]\n",
    "cov = [[.7, 0], [0, .7]]\n",
    "N = 20\n",
    "\n",
    "X1 = np.random.multivariate_normal(means[0], cov, N)\n",
    "X2 = np.random.multivariate_normal(means[1], cov, N)\n",
    "X_2D = np.vstack((X1, X2))\n",
    "y_2D = np.array([0]*N + [1]*N)\n",
    "\n",
    "start = time.time()\n",
    "logReg2 = linear_model.LogisticRegression(penalty='l2')\n",
    "logReg2.fit(X_2D, y_2D)\n",
    "end = time.time()\n",
    "\n",
    "y_pred2 = logReg2.predict(X_2D)\n",
    "\n",
    "print(\"üîπ [B·ªô 2D] Logistic Regression (Scikit-learn)\")\n",
    "print(\"Coefficients:\", logReg2.coef_)\n",
    "print(\"Intercept   :\", logReg2.intercept_)\n",
    "print(\"Accuracy :\", accuracy_score(y_2D, y_pred2))\n",
    "print(\"Precision:\", precision_score(y_2D, y_pred2))\n",
    "print(\"Recall   :\", recall_score(y_2D, y_pred2))\n",
    "print(\"Time     :\", end - start)\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_2D, y_pred2))\n"
   ],
   "id": "e9d19d3dae7111ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ [B·ªô 1D] Logistic Regression (Scikit-learn)\n",
      "Coefficients: [[1.14881183]]\n",
      "Intercept   : [-3.14004565]\n",
      "Accuracy : 0.8\n",
      "Precision: 0.8\n",
      "Recall   : 0.8\n",
      "Time     : 0.0075550079345703125\n",
      "Confusion matrix:\n",
      " [[8 2]\n",
      " [2 8]]\n",
      "------------------------------------------------------------\n",
      "üîπ [B·ªô 2D] Logistic Regression (Scikit-learn)\n",
      "Coefficients: [[ 2.13771786 -0.0576235 ]]\n",
      "Intercept   : [-6.1466587]\n",
      "Accuracy : 0.925\n",
      "Precision: 0.9473684210526315\n",
      "Recall   : 0.9\n",
      "Time     : 0.00414729118347168\n",
      "Confusion matrix:\n",
      " [[19  1]\n",
      " [ 2 18]]\n"
     ]
    }
   ],
   "execution_count": 574
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9292213f0b6c41f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# B√†i 2",
   "id": "6a54a30f91371d0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:23.365760Z",
     "start_time": "2025-10-16T14:14:23.360808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import time"
   ],
   "id": "e70d5c28738a1009",
   "outputs": [],
   "execution_count": 575
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:25.175476Z",
     "start_time": "2025-10-16T14:14:25.023520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"banking.csv\")\n",
    "data.head()"
   ],
   "id": "c79969b64722d1af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age          job  marital          education  default housing loan  \\\n",
       "0   44  blue-collar  married           basic.4y  unknown     yes   no   \n",
       "1   53   technician  married            unknown       no      no   no   \n",
       "2   28   management   single  university.degree       no     yes   no   \n",
       "3   39     services  married        high.school       no      no   no   \n",
       "4   55      retired  married           basic.4y       no     yes   no   \n",
       "\n",
       "    contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
       "0  cellular   aug         thu  ...         1    999         0  nonexistent   \n",
       "1  cellular   nov         fri  ...         1    999         0  nonexistent   \n",
       "2  cellular   jun         thu  ...         3      6         2      success   \n",
       "3  cellular   apr         fri  ...         2    999         0  nonexistent   \n",
       "4  cellular   aug         fri  ...         1      3         1      success   \n",
       "\n",
       "  emp_var_rate  cons_price_idx  cons_conf_idx  euribor3m  nr_employed  y  \n",
       "0          1.4          93.444          -36.1      4.963       5228.1  0  \n",
       "1         -0.1          93.200          -42.0      4.021       5195.8  0  \n",
       "2         -1.7          94.055          -39.8      0.729       4991.6  1  \n",
       "3         -1.8          93.075          -47.1      1.405       5099.1  0  \n",
       "4         -2.9          92.201          -31.4      0.869       5076.2  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>cons_price_idx</th>\n",
       "      <th>cons_conf_idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr_employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.021</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>thu</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>success</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.055</td>\n",
       "      <td>-39.8</td>\n",
       "      <td>0.729</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>apr</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>93.075</td>\n",
       "      <td>-47.1</td>\n",
       "      <td>1.405</td>\n",
       "      <td>5099.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>success</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.201</td>\n",
       "      <td>-31.4</td>\n",
       "      <td>0.869</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 576
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:26.723414Z",
     "start_time": "2025-10-16T14:14:26.536606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dict_month = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6,\n",
    "              'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
    "data['month'] = data['month'].map(dict_month)\n",
    "\n",
    "dict_day = {'mon':1, 'tue':2, 'wed':3, 'thu':4, 'fri':5}\n",
    "data['day_of_week'] = data['day_of_week'].map(dict_day)\n",
    "\n",
    "# Convert binary fields\n",
    "for col in ['default', 'housing', 'loan']:\n",
    "    data[col] = data[col].replace({'no':0, 'yes':1, 'unknown':0}).astype(int)\n",
    "\n",
    "# Convert pdays: -1 or 999 ‚Üí 0 (not contacted), else 1\n",
    "data['pdays'] = data['pdays'].apply(lambda x: 0 if x in [-1, 999] else 1)\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "categorical_cols = ['job', 'marital', 'education', 'contact', 'poutcome']\n",
    "for col in categorical_cols:\n",
    "    dummies = pd.get_dummies(data[col], prefix=col, drop_first=True).astype(int)\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "    data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Encode target variable\n",
    "data['y'] = data['y'].replace({'no':0, 'yes':1}).astype(int)"
   ],
   "id": "92a6fb17ddd8fe61",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17188\\4088146044.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'no':0, 'yes':1, 'unknown':0}).astype(int)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17188\\4088146044.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'no':0, 'yes':1, 'unknown':0}).astype(int)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_17188\\4088146044.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[col] = data[col].replace({'no':0, 'yes':1, 'unknown':0}).astype(int)\n"
     ]
    }
   ],
   "execution_count": 577
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:28.595372Z",
     "start_time": "2025-10-16T14:14:28.554126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = data.dropna()\n",
    "X = data.drop('y', axis=1).values.T\n",
    "y = data['y'].values\n",
    "X = np.vstack([np.ones((1, X.shape[1])), X]).T"
   ],
   "id": "3cbff83982077e3",
   "outputs": [],
   "execution_count": 578
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:29.930051Z",
     "start_time": "2025-10-16T14:14:29.922203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(s):\n",
    "    s = np.clip(s, -500, 500)\n",
    "    return 1 / (1 + np.exp(-s))\n",
    "def logistic_sigmoid_regression(X, y, w_init, eta, tol=1e-4, max_count=10000):\n",
    "    w = [w_init]\n",
    "    it = 0\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    count = 0\n",
    "    check_w_after = 20\n",
    "    while count < max_count:\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = y[i]\n",
    "            zi = sigmoid(np.dot(w[-1].T, xi))\n",
    "            w_new = w[-1] + eta * (yi - zi) * xi\n",
    "            count += 1\n",
    "            if count % check_w_after == 0:\n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol:\n",
    "                    return w\n",
    "            w.append(w_new)\n",
    "    return w"
   ],
   "id": "c3e8b03925c0086a",
   "outputs": [],
   "execution_count": 579
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:31.939405Z",
     "start_time": "2025-10-16T14:14:31.933671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = int(0.8 * len(X))\n",
    "X_train = X[:train_size,:]\n",
    "Y_train =y[:train_size]\n",
    "X_test = X[train_size:,:]\n",
    "Y_test = y[train_size:]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ],
   "id": "f359b941570d2f05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32950, 40)\n",
      "(8238, 40)\n"
     ]
    }
   ],
   "execution_count": 580
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:49.150177Z",
     "start_time": "2025-10-16T14:14:49.134668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d = X_train.shape[1]\n",
    "w_init = np.random.randn(d, 1)\n",
    "eta = 0.01\n",
    "w = logistic_sigmoid_regression(X_train.T, Y_train, w_init, eta)\n",
    "print(w[-1].shape)"
   ],
   "id": "e269ee6e7d33de50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n"
     ]
    }
   ],
   "execution_count": 586
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:50.311322Z",
     "start_time": "2025-10-16T14:14:50.299073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_log = time.time()\n",
    "y_prod = sigmoid(np.dot(w[-1].T, X_test.T))\n",
    "y_pred = (y_prod >= 0.5).astype(int)\n",
    "end_log = time.time()\n",
    "print(\"C√°c h·ªá s·ªë c·ªßa m√¥ h√¨nh (w):\")\n",
    "print(w[-1].flatten())\n",
    "TP = np.sum((y_pred == 1) & (Y_test == 1))\n",
    "TN = np.sum((y_pred == 0) & (Y_test == 0))\n",
    "FP = np.sum((y_pred == 1) & (Y_test == 0))\n",
    "FN = np.sum((y_pred == 0) & (Y_test == 1))\n",
    "\n",
    "accuracy = (TP + TN) / len(Y_test)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f\"\\nƒê·ªô ch√≠nh x√°c (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"ƒê·ªô ch√≠nh x√°c d∆∞∆°ng (Precision): {precision:.4f}\")\n",
    "print(f\"ƒê·ªô nh·∫°y (Recall): {recall:.4f}\")\n",
    "print(f\"F1(B=1) score = {f1}\")\n",
    "print(f\"Time: {-start_log+end_log}\")"
   ],
   "id": "887f4252d63a9998",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√°c h·ªá s·ªë c·ªßa m√¥ h√¨nh (w):\n",
      "[ -0.56656923   0.8609371    0.80833802  -0.5727334    0.15490466\n",
      "   0.08641403   0.37425023  63.86299494  -2.08093648   1.30233708\n",
      "  -1.18065667   0.29458534  -1.40451428   1.17974318   1.60598918\n",
      " -21.85639303   1.03961411  -0.46623334  -0.50144342   0.11174559\n",
      "   0.21033231  -0.37179718  -0.95858394  -0.55374778  -1.20354252\n",
      "   0.64654851   1.05381195   0.8820719    0.28512831   1.11706335\n",
      "  -1.78375321  -0.96735713  -0.66337457   0.3485401    0.190321\n",
      "   2.11044818   1.7534363    1.40249241  -1.44580391  -1.42462164]\n",
      "\n",
      "ƒê·ªô ch√≠nh x√°c (Accuracy): 0.8934\n",
      "ƒê·ªô ch√≠nh x√°c d∆∞∆°ng (Precision): 0.6522\n",
      "ƒê·ªô nh·∫°y (Recall): 0.0169\n",
      "F1(B=1) score = 0.03303964757709251\n",
      "Time: 0.002248525619506836\n"
     ]
    }
   ],
   "execution_count": 587
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:55.601342Z",
     "start_time": "2025-10-16T14:14:55.592586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gaussian_prob(x, mean, std):\n",
    "    std = max(std, 1e-6)\n",
    "    return (1 / (sqrt(2*pi) * std)) * exp(- ((x - mean)**2) / (2*std**2))\n",
    "\n",
    "def train_gnb(X, y):\n",
    "    classes = np.unique(y)\n",
    "    mu_list = []\n",
    "    std_list = []\n",
    "    pi_list = []\n",
    "    for c in classes:\n",
    "        X_c = X[y==c]\n",
    "        mu_list.append(X_c.mean(axis=0))\n",
    "        std_list.append(X_c.std(axis=0))\n",
    "        pi_list.append(len(X_c)/len(X))\n",
    "    return np.array(mu_list), np.array(std_list), np.array(pi_list)\n",
    "\n",
    "def predict_gnb(X, mu_list, std_list, pi_list):\n",
    "    y_pred = []\n",
    "    for x in X:\n",
    "        scores = []\n",
    "        for mu, std, pi_c in zip(mu_list, std_list, pi_list):\n",
    "            likelihood = np.prod([gaussian_prob(xi, mui, si) for xi, mui, si in zip(x, mu, std)])\n",
    "            scores.append(likelihood * pi_c)\n",
    "        y_pred.append(np.argmax(scores))\n",
    "    return np.array(y_pred)"
   ],
   "id": "4a18d36e32f71fbb",
   "outputs": [],
   "execution_count": 588
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:58.379573Z",
     "start_time": "2025-10-16T14:14:57.517947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_logNB = time.time()\n",
    "mu_list, std_list, pi_list = train_gnb(X_train, Y_train)\n",
    "y_pred_nb = predict_gnb(X_test, mu_list, std_list, pi_list)\n",
    "end_logNB = time.time()"
   ],
   "id": "4779d7dd8a85ae22",
   "outputs": [],
   "execution_count": 589
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:14:59.640335Z",
     "start_time": "2025-10-16T14:14:59.633976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    TP = np.sum((y_true==1) & (y_pred==1))\n",
    "    TN = np.sum((y_true==0) & (y_pred==0))\n",
    "    FP = np.sum((y_true==0) & (y_pred==1))\n",
    "    FN = np.sum((y_true==1) & (y_pred==0))\n",
    "\n",
    "    accuracy = (TP + TN)/len(y_true)\n",
    "    precision = TP/(TP+FP) if (TP+FP)>0 else 0\n",
    "    recall = TP/(TP+FN) if (TP+FN)>0 else 0\n",
    "    f1 = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0\n",
    "    return accuracy, precision, recall, f1, (TP, TN, FP, FN)"
   ],
   "id": "d591523cd073a398",
   "outputs": [],
   "execution_count": 590
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:15:01.701710Z",
     "start_time": "2025-10-16T14:15:01.695121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cc_nb, pre_nb, rec_nb, f1_nb, conf_nb = evaluate(Y_test, y_pred_nb)\n",
    "print(\"\\n=== Gaussian Naive Bayes ===\")\n",
    "print(f\"Accuracy: {acc_nb:.4f}, Precision: {pre_nb:.4f}, Recall: {rec_nb:.4f}, F1: {f1_nb:.4f}\")\n",
    "print(f\"Time: {end_logNB - start_logNB}\")"
   ],
   "id": "ada7bdb240c987ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Gaussian Naive Bayes ===\n",
      "Accuracy: 0.8700, Precision: 0.2217, Recall: 0.8847, F1: 0.3545\n",
      "Time: 0.8575026988983154\n"
     ]
    }
   ],
   "execution_count": 591
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# B√†i 3",
   "id": "fc7ed457e0b78738"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import pandas as pd",
   "id": "a4c826b57cd2b6d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:10:32.330301Z",
     "start_time": "2025-10-16T14:10:32.308925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv(\"framingham.csv\")\n",
    "data = data.dropna(how=\"any\", axis = 0)"
   ],
   "id": "66a98d9966a96c78",
   "outputs": [],
   "execution_count": 508
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:10:33.489421Z",
     "start_time": "2025-10-16T14:10:33.478266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(s):\n",
    "    s = np.clip(s, -500, 500)\n",
    "    return 1 / (1 + np.exp(-s))\n",
    "def logistic_sigmoid_regression(X, y, w_init, eta, tol=1e-4, max_count=10000):\n",
    "    w = [w_init]\n",
    "    it = 0\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    count = 0\n",
    "    check_w_after = 20\n",
    "    while count < max_count:\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = y[i]\n",
    "            zi = sigmoid(np.dot(w[-1].T, xi))\n",
    "            w_new = w[-1] + eta * (yi - zi) * xi\n",
    "            count += 1\n",
    "            if count % check_w_after == 0:\n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol:\n",
    "                    return w\n",
    "            w.append(w_new)\n",
    "    return w"
   ],
   "id": "d32106fd997b3fad",
   "outputs": [],
   "execution_count": 509
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:10:36.570540Z",
     "start_time": "2025-10-16T14:10:36.562228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = data.drop('TenYearCHD', axis=1).values.T\n",
    "y = data['TenYearCHD'].values\n",
    "X = np.vstack([np.ones((1, X.shape[1])), X]).T\n",
    "print(X)\n"
   ],
   "id": "9a94fffd7ffeddf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.     1.    39.   ...  26.97  80.    77.  ]\n",
      " [  1.     0.    46.   ...  28.73  95.    76.  ]\n",
      " [  1.     1.    48.   ...  25.34  75.    70.  ]\n",
      " ...\n",
      " [  1.     1.    50.   ...  25.97  66.    86.  ]\n",
      " [  1.     1.    51.   ...  19.71  65.    68.  ]\n",
      " [  1.     0.    52.   ...  21.47  80.   107.  ]]\n"
     ]
    }
   ],
   "execution_count": 510
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:10:37.543063Z",
     "start_time": "2025-10-16T14:10:37.538574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = int(0.7 * len(X))\n",
    "X_train = X[:train_size,:]\n",
    "Y_train =y[:train_size]\n",
    "X_test = X[train_size:,:]\n",
    "Y_test = y[train_size:]\n",
    "X_mean = X_train[:,1:].mean(axis=0)\n",
    "X_std = X_train[:,1:].std(axis=0)\n",
    "X_train[:,1:] = (X_train[:,1:] - X_mean)/X_std\n",
    "X_test[:,1:] = (X_test[:,1:] - X_mean)/X_std"
   ],
   "id": "5f51fe98f2bd5640",
   "outputs": [],
   "execution_count": 511
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:10:38.923170Z",
     "start_time": "2025-10-16T14:10:38.787420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d = X_train.shape[1]\n",
    "w_init = np.random.randn(d, 1)\n",
    "eta = 0.01\n",
    "w = logistic_sigmoid_regression(X_train.T, Y_train, w_init, eta)\n",
    "print(w[-1])"
   ],
   "id": "f9d871ea3a3fb9cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.00344629]\n",
      " [ 0.18568988]\n",
      " [ 0.56995806]\n",
      " [-0.07460883]\n",
      " [ 0.01385394]\n",
      " [ 0.22598039]\n",
      " [-0.01642637]\n",
      " [-0.03987643]\n",
      " [ 0.06879666]\n",
      " [-0.01064966]\n",
      " [ 0.19359789]\n",
      " [ 0.33345862]\n",
      " [-0.13788236]\n",
      " [ 0.06065003]\n",
      " [-0.06920722]\n",
      " [ 0.20566252]]\n"
     ]
    }
   ],
   "execution_count": 512
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:10:52.514807Z",
     "start_time": "2025-10-16T14:10:52.504645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_log = time.time()\n",
    "y_prod = sigmoid(np.dot(w[-1].T, X_test.T))\n",
    "y_pred = (y_prod > 0.5).astype(int)\n",
    "end_log = time.time()\n",
    "print(\"C√°c h·ªá s·ªë c·ªßa m√¥ h√¨nh (w):\")\n",
    "print(w[-1].flatten())\n",
    "TP = np.sum((y_pred == 1) & (Y_test == 1))\n",
    "TN = np.sum((y_pred == 0) & (Y_test == 0))\n",
    "FP = np.sum((y_pred == 1) & (Y_test == 0))\n",
    "FN = np.sum((y_pred == 0) & (Y_test == 1))\n",
    "\n",
    "accuracy = (TP + TN) / len(Y_test)\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f\"\\nƒê·ªô ch√≠nh x√°c (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"ƒê·ªô ch√≠nh x√°c d∆∞∆°ng (Precision): {precision:.4f}\")\n",
    "print(f\"ƒê·ªô nh·∫°y (Recall): {recall:.4f}\")\n",
    "print(f\"F1(B=1) score = {f1}\")\n",
    "print(f\"Time: {-start_log+end_log}\")"
   ],
   "id": "46e5159184a60375",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C√°c h·ªá s·ªë c·ªßa m√¥ h√¨nh (w):\n",
      "[-2.00344629  0.18568988  0.56995806 -0.07460883  0.01385394  0.22598039\n",
      " -0.01642637 -0.03987643  0.06879666 -0.01064966  0.19359789  0.33345862\n",
      " -0.13788236  0.06065003 -0.06920722  0.20566252]\n",
      "\n",
      "ƒê·ªô ch√≠nh x√°c (Accuracy): 0.8505\n",
      "ƒê·ªô ch√≠nh x√°c d∆∞∆°ng (Precision): 0.6250\n",
      "ƒê·ªô nh·∫°y (Recall): 0.0301\n",
      "F1(B=1) score = 0.057471264367816084\n",
      "Time: 0.00078582763671875\n"
     ]
    }
   ],
   "execution_count": 519
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
